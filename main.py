import streamlit as st
from langchain.memory import ConversationSummaryBufferMemory
from langchain_openai import ChatOpenAI
from get_gptresponse import get_gptresponse
st.title("ğŸ¤–æ€é¢–èŠå¤©æœºå™¨äºº")
#ä¾§è¾¹æ¡†
with st.sidebar:
    openai_key=st.text_input("è¯·è¾“å…¥OpenAI APIå¯†é’¥")
    st.markdown("[å¦‚ä½•è·å–OpenAI APIå¯†é’¥ï¼Ÿ](https://openai.com/index/chatgpt/)")
#åˆå§‹èŠå¤©ç•Œé¢ï¼š
if "memory" not in st.session_state:
    model = ChatOpenAI(model='gpt-3.5-turbo',
                      api_key=openai_key,
                      openai_api_base="https://api.aigc369.com/v1")
    st.session_state["memory"]=ConversationSummaryBufferMemory(
        llm=model,max_token_limit=2000,return_messages=True
    )
    st.session_state["message"]=[{"role":"ai",
                                  "context":"ä½ å¥½ï¼Œæ€é¢–æœºå™¨äººä¸ºæ‚¨æœåŠ¡ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°ä½ çš„å—ï¼Ÿ"}]
for message in st.session_state["message"]:
    st.chat_message(message["role"]).write(message["context"])
##è¯¢é—®å¼€å§‹
prompt=st.chat_input("æ‚¨æƒ³äº†è§£ä¸€äº›ä»€ä¹ˆï¼Ÿæ€é¢–æ¥å‘Šè¯‰ä½ ")
if prompt:
    if openai_key == '':
        st.info("è¯·è¾“å…¥OpenAI APIå¯†é’¥")
        st.stop()
    else:
        st.chat_message('human').write(prompt)
        st.session_state["message"].append({"role":"human","context":prompt})
##é—®é¢˜å¤„ç†
        with st.spinner("ğŸ‘©æ€é¢–æ­£åœ¨æ€è€ƒå“¦ï¼Œè¯·ç¨ç­‰"):
            result=get_gptresponse(prompt,st.session_state["memory"],openai_key)
        st.chat_message('ai').write(result)
        st.session_state["message"].append({"role":"ai","context":result})
